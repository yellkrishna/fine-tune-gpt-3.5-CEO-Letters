{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "KEojjKQiNQr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this exercise is to identify the existence of a few dimensions in letters written by CEOs to shareholders using OpenAI’s language model. The language model is accessed using OpenAI’s API. The model is first fine-tuned using the three training datasets provided and the test dataset is used as a test set. We check the predicted dimensions for the test dataset and compare it with the true values. The accuracy of the prediction is calculated."
      ],
      "metadata": {
        "id": "A0K1ShNwNSAp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ravK1MmtFLbF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import drive\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGqiPXHgzzCu",
        "outputId": "cdd3a6a3-c29f-4315-fcb4-4aa4f111fcd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "LhYZ3ZtVFkqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess the Data:\n",
        "We are using the provided three training datasets as the training set and the test dataset as the test set. In this step, we concatenated the three datasets to create a single training set."
      ],
      "metadata": {
        "id": "Hw73aafDRWuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_train_data(train_files):\n",
        "  # Load data from Excel files\n",
        "  df_train = pd.concat([pd.read_excel(file) for file in train_files])\n",
        "\n",
        "  # Handling Missing Values\n",
        "  # Replace missing values with a placeholder or drop rows with missing values\n",
        "  df_train.dropna(subset=['paragraph'], inplace=True)\n",
        "\n",
        "  \"\"\"# Download stopwords corpus (if not already downloaded)\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('punkt')\"\"\"\n",
        "\n",
        "  # Preprocess the text data\n",
        "  # Lower-Case words\n",
        "  df_train['processed_paragraph'] = df_train['paragraph'].apply(lambda text: text.lower())\n",
        "\n",
        "  return df_train"
      ],
      "metadata": {
        "id": "AZLvTyZ3FjgS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = r'/content/drive/MyDrive/GRA_KU_Assessment/TEST/train_files'\n",
        "# Get a list of all files in the folder\n",
        "files_in_folder = os.listdir(folder_path)\n",
        "# Filter Excel files with specific names (train1, train2, train3, etc.)\n",
        "train_files = [os.path.join(folder_path, file) for file in files_in_folder if file.startswith('train') and file.endswith('.xlsx')]\n",
        "df_train = load_and_preprocess_train_data(train_files)"
      ],
      "metadata": {
        "id": "AFSqb9liISK6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Fine-tuning\n",
        "In this step, we convert our data into the format required for the OpenAI API.\n",
        "\n",
        "We convert the data from the table format (.xlsx format) provided to a Chat Completions API format that is accepted by OpenAI’s API. This format is a list of messages where each message has a role and content.\n",
        "\n",
        "In our training set, for each message in the requirem format will have three components for each datapoint (sentence) with each playing a different role. The first part of the message plays the role of *system*. This is where we give precise instructions to the model as to what we expect it to do. The next part of the message plays the role of *user* which contains portions of the letters from CEOs. This is supposed to be the input for fine-tuning process. The last part of the message plays the role of *assistant*, which is the result from which we want it to fine-tune. This is the training part."
      ],
      "metadata": {
        "id": "3T2nRAbxGjAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_fine_tuning(df_train):\n",
        "  # Convert the 'paragraph' column to a list\n",
        "  paragraphs = df_train['processed_paragraph'].tolist()\n",
        "\n",
        "  # Create a list to store the formatted data\n",
        "  train_data = []\n",
        "\n",
        "  # Iterate through each row in the DataFrame and create prompt-completion pairs\n",
        "  for index, row in df_train.iterrows():\n",
        "      prompt = row['processed_paragraph']\n",
        "      # Convert 'Yes' and 'No' to 1 and 0, respectively\n",
        "      completion = ','.join(['1' if row[col] == 'Yes' else '0' for col in df_train.columns[1:]])\n",
        "      train_data.append({\"prompt\": prompt, \"completion\": completion})\n",
        "\n",
        "  # Display a few examples to verify the format\n",
        "  for example in train_data[:1]:\n",
        "      print(example)\n",
        "\n",
        "  return train_data"
      ],
      "metadata": {
        "id": "zXRYP5lMF95a"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_chat_completion(prompt_completion_data):\n",
        "    chat_completion_data = []\n",
        "\n",
        "    for entry in prompt_completion_data:\n",
        "        prompt = entry['prompt']\n",
        "        completion = entry['completion']\n",
        "\n",
        "        # Extracting the completion details and converting them into the desired format\n",
        "        completion_details = [f\"{key}: {'Yes' if value == '1' else 'No'}\" for key, value in zip(['Goal', 'Activity', 'Strategy', 'Plan', 'Structure', 'Innovation', 'Tactics', 'Relevance'], completion.split(','))]\n",
        "\n",
        "        # Joining the completion details into a single string\n",
        "        completion_text = ', '.join(completion_details)\n",
        "\n",
        "        # Creating the chat-completion format\n",
        "        conversation = {\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": \"Use the folowing step-by-step instructon to respond to the user inputs. Step 1 - In the user content which is taken from letters written by CEO to shareholders, you have to identify the existence of dimensions/qualities that are provided in this list given in brackets and that are seperated by commas ['Goal', 'Activity', 'Strategy', 'Plan', 'Structure', 'Innovation', 'Tactics', 'Relevance']. Step 2 - For each of these dimensions, if the dimension exists in the user prompt based on the assistant content I provide to you in the fine-tuning data, answer Yes, otherwise answer No. After step2, this is an example output whose template you must use to provide your answer - ['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: No, Relevance: No']\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "                {\"role\": \"assistant\", \"content\": completion_text}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        chat_completion_data.append(conversation)\n",
        "\n",
        "    return chat_completion_data\n"
      ],
      "metadata": {
        "id": "HGwVnntB3kOA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = prepare_data_for_fine_tuning(df_train)\n",
        "train_data = convert_to_chat_completion(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUVbpIvkInFY",
        "outputId": "bdd7e60d-d238-4b95-e204-8b8efb90399d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': 'february 24, 2011\\nto our shareholders:\\n2010 was another challenging year for sears holdings.  our financial results remain at unacceptable levels, and we are working to drive better performance in both the short and long term.  the company generates significant amounts of cash, and we have the ability and flexibility to invest that cash strategically.  we will continue to make long-term investments in key areas that may adversely impact short-term results when we believe they will generate attractive long-term returns.  in particular, we have significantly grown our shop your way rewards program, improved our online and mobile platforms, and re-examined our overall technology infrastructure.  we believe these investments are an important part of transforming sears holdings into a truly integrated retail company, focusing on customers first', 'completion': '0,1,1,1,1,1,0,0,1,0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x685jK79IunK",
        "outputId": "403ec78e-d507-4c36-f667-e5d969e9fcc3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [{'role': 'system', 'content': \"Use the folowing step-by-step instructon to respond to the user inputs. Step 1 - In the user content which is taken from letters written by CEO to\\xa0shareholders, you have to identify the existence of dimensions/qualities that are provided in this list given in brackets and that are seperated by commas ['Goal', 'Activity', 'Strategy', 'Plan', 'Structure', 'Innovation', 'Tactics', 'Relevance']. Step 2 - For each of these dimensions, if the dimension exists in the user prompt based on the assistant content I provide to you in the fine-tuning data, answer Yes, otherwise answer No. After step2, this is an example output whose template you must use to provide your answer - ['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: No, Relevance: No']\"}, {'role': 'user', 'content': 'february 24, 2011\\nto our shareholders:\\n2010 was another challenging year for sears holdings.  our financial results remain at unacceptable levels, and we are working to drive better performance in both the short and long term.  the company generates significant amounts of cash, and we have the ability and flexibility to invest that cash strategically.  we will continue to make long-term investments in key areas that may adversely impact short-term results when we believe they will generate attractive long-term returns.  in particular, we have significantly grown our shop your way rewards program, improved our online and mobile platforms, and re-examined our overall technology infrastructure.  we believe these investments are an important part of transforming sears holdings into a truly integrated retail company, focusing on customers first'}, {'role': 'assistant', 'content': 'Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: No, Relevance: No'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune the model\n",
        "We invoke an OpenAI model, feed the training data and finetune it. The base model used for fine-tuning is gpt-3.5-turbo."
      ],
      "metadata": {
        "id": "tQON5n4_HNWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(train_data, api_key):\n",
        "  # Assuming train_data contains your prompt-completion pairs\n",
        "  # Save the train_data in JSON Lines format\n",
        "  with open(\"/content/drive/MyDrive/GRA_KU_Assessment/TEST/mydata.jsonl\", \"w\") as file:\n",
        "      for example in train_data:\n",
        "          file.write(json.dumps(example) + \"\\n\")\n",
        "\n",
        "  # Initialize the OpenAI client\n",
        "  client = OpenAI(api_key= api_key)\n",
        "\n",
        "  # Upload the JSON Lines file for fine-tuning\n",
        "  try:\n",
        "    resp1 = client.files.create(\n",
        "        file=open(\"/content/drive/MyDrive/GRA_KU_Assessment/TEST/mydata.jsonl\", \"rb\"),\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "    print(\"File uploaded successfully.\")\n",
        "  except Exception as e:\n",
        "    print(\"File upload failed:\", e)\n",
        "    return None, None\n",
        "\n",
        "  # Create the fine-tuning job\n",
        "  try:\n",
        "    resp2 = client.fine_tuning.jobs.create(\n",
        "    training_file=resp1.id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        "    )\n",
        "    print(\"Fine-tuning job created successfully.\")\n",
        "  except Exception as e:\n",
        "    print(\"Fine-tuning job creation failed:\", e)\n",
        "    return None, None\n",
        "\n",
        "  # Check the status of the fine-tuning job\n",
        "  while True:\n",
        "    resp3 = client.fine_tuning.jobs.retrieve(resp2.id)\n",
        "    status = resp3.status\n",
        "    print(\"Fine-tuning job status:\", status)\n",
        "    if status == \"succeeded\":\n",
        "      print(\"Fine-tuning job completed successfully.\")\n",
        "      break\n",
        "    elif status == \"failed\":\n",
        "      print(\"Fine-tuning job failed:\", resp3.error)\n",
        "      break\n",
        "    elif status == \"cancelled\":\n",
        "      print(\"Fine-tuning job cancelled by user.\")\n",
        "      break\n",
        "    else:\n",
        "      print(\"Fine-tuning job in progress. Please wait...\")\n",
        "      time.sleep(60)\n",
        "\n",
        "  return resp2, client\n"
      ],
      "metadata": {
        "id": "2YStub91PVdZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = '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'\n",
        "response, client = fine_tune_model(train_data, api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOi9ZoG7IyfV",
        "outputId": "5871723d-37f7-471a-d42a-6838081e0b83"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded successfully.\n",
            "Fine-tuning job created successfully.\n",
            "Fine-tuning job status: validating_files\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: running\n",
            "Fine-tuning job in progress. Please wait...\n",
            "Fine-tuning job status: succeeded\n",
            "Fine-tuning job completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLptqQH1I1u8",
        "outputId": "53849dfe-2e2b-4787-e73c-af78d9aef14f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FineTuningJob(id='ftjob-catQFwicDtVbb6bZYZbg2GLC', created_at=1700433191, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-BNdO85mmDzyE4YWAlVvz9Z2A', result_files=[], status='validating_files', trained_tokens=None, training_file='file-4cqRSlKO9x0qpMQnshCjjOtU', validation_file=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess the test data\n",
        "We load the test data and do the necessary preprocessing. This is the test.xslx data."
      ],
      "metadata": {
        "id": "z9RbH12CHu_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_test_data(test_file):\n",
        "  # Load data from the test file\n",
        "  df_test = pd.read_excel(test_file)\n",
        "\n",
        "  # Preprocess the text data similar to the training data\n",
        "  df_test['processed_paragraph'] = df_test['paragraph'].apply(lambda text: text.lower())\n",
        "\n",
        "  return df_test"
      ],
      "metadata": {
        "id": "E2ynN6GgH0kv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = r\"/content/drive/MyDrive/GRA_KU_Assessment/TEST/test_file/test.xlsx\"\n",
        "df_test = load_and_preprocess_test_data(test_file)"
      ],
      "metadata": {
        "id": "9jXK3BzLI8jR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Predictions\n",
        "We now use the fine-tuned model and feed in the test set provided. We will use the results from the test set to assess the model’s performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "-erB24WCIADL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(df_test, fine_tuned_model_id, client):\n",
        "  # Get the sentences to test from the dataframe\n",
        "  sentences_to_test = df_test['processed_paragraph'].tolist()\n",
        "  # Initialize an empty list to store the responses\n",
        "  responses = []\n",
        "  # Set the batch size for chat completions\n",
        "  batch_size = 10\n",
        "  # Loop through the sentences in batches\n",
        "  for i in range(0, len(sentences_to_test), batch_size):\n",
        "    # Get the current batch of sentences\n",
        "    batch = sentences_to_test[i:i+batch_size]\n",
        "    # Loop through the sentences in the batch\n",
        "    for ind, sentence in enumerate(batch):\n",
        "      # Create the system and user messages for each sentence\n",
        "      messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Use the folowing step-by-step instructon to respond to the user inputs. Step 1 - In the user content which is taken from letters written by CEO to shareholders, you have to identify the existence of dimensions/qualities that are provided in this list given in brackets and that are seperated by commas ['Goal', 'Activity', 'Strategy', 'Plan', 'Structure', 'Innovation', 'Tactics', 'Relevance']. Step 2 - For each of these dimensions, if the dimension exists in the user prompt based on the assistant content I provide to you in the fine-tuning data, answer Yes, otherwise answer No. After step2, this is an example output whose template you must use to provide your answer - ['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: No, Relevance: No']\"},\n",
        "        {\"role\": \"user\", \"content\": sentence}\n",
        "      ]\n",
        "      # Try to make a chat completion for the sentence\n",
        "      try:\n",
        "        response = client.chat.completions.create(\n",
        "        model=fine_tuned_model_id,\n",
        "        messages=messages\n",
        "        )\n",
        "        print(\"Chat completion succeeded for sentence\", ind, \" and batch \", i)\n",
        "      # Handle any errors or exceptions\n",
        "      except Exception as e:\n",
        "        print(\"Chat completion failed for sentence\", ind, \" and batch \", i, \":\", e)\n",
        "        return None\n",
        "      # Append the assistant message content to the responses list\n",
        "      responses.append(response.choices[0].message.content)\n",
        "\n",
        "  # Return the responses list\n",
        "  return responses\n"
      ],
      "metadata": {
        "id": "jrNXT29XS2Te"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_id = \"gpt-3.5-turbo\"\n",
        "predictions = make_predictions(df_test, fine_tuned_model_id, client)"
      ],
      "metadata": {
        "id": "_NEqRmO0Kqu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98171ee-c067-47f1-c727-00dc7c03b8b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat completion succeeded for sentence 0  and batch  0\n",
            "Chat completion succeeded for sentence 1  and batch  0\n",
            "Chat completion succeeded for sentence 2  and batch  0\n",
            "Chat completion succeeded for sentence 3  and batch  0\n",
            "Chat completion succeeded for sentence 4  and batch  0\n",
            "Chat completion succeeded for sentence 5  and batch  0\n",
            "Chat completion succeeded for sentence 6  and batch  0\n",
            "Chat completion succeeded for sentence 7  and batch  0\n",
            "Chat completion succeeded for sentence 8  and batch  0\n",
            "Chat completion succeeded for sentence 9  and batch  0\n",
            "Chat completion succeeded for sentence 0  and batch  10\n",
            "Chat completion succeeded for sentence 1  and batch  10\n",
            "Chat completion succeeded for sentence 2  and batch  10\n",
            "Chat completion succeeded for sentence 3  and batch  10\n",
            "Chat completion succeeded for sentence 4  and batch  10\n",
            "Chat completion succeeded for sentence 5  and batch  10\n",
            "Chat completion succeeded for sentence 6  and batch  10\n",
            "Chat completion succeeded for sentence 7  and batch  10\n",
            "Chat completion succeeded for sentence 8  and batch  10\n",
            "Chat completion succeeded for sentence 9  and batch  10\n",
            "Chat completion succeeded for sentence 0  and batch  20\n",
            "Chat completion succeeded for sentence 1  and batch  20\n",
            "Chat completion succeeded for sentence 2  and batch  20\n",
            "Chat completion succeeded for sentence 3  and batch  20\n",
            "Chat completion succeeded for sentence 4  and batch  20\n",
            "Chat completion succeeded for sentence 5  and batch  20\n",
            "Chat completion succeeded for sentence 6  and batch  20\n",
            "Chat completion succeeded for sentence 7  and batch  20\n",
            "Chat completion succeeded for sentence 8  and batch  20\n",
            "Chat completion succeeded for sentence 9  and batch  20\n",
            "Chat completion succeeded for sentence 0  and batch  30\n",
            "Chat completion succeeded for sentence 1  and batch  30\n",
            "Chat completion succeeded for sentence 2  and batch  30\n",
            "Chat completion succeeded for sentence 3  and batch  30\n",
            "Chat completion succeeded for sentence 4  and batch  30\n",
            "Chat completion succeeded for sentence 5  and batch  30\n",
            "Chat completion succeeded for sentence 6  and batch  30\n",
            "Chat completion succeeded for sentence 7  and batch  30\n",
            "Chat completion succeeded for sentence 8  and batch  30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf7491Xs57YC",
        "outputId": "9c9de7b0-ce4b-469f-cf7b-65da0e700b89"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: Yes, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: Yes, Plan: Yes, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: Yes, Plan: Yes, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: No, Structure: Yes, Innovation: No, Tactics: No, Relevance: Yes']\", \"['Goal: Yes, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: No, Tactics: No, Relevance: Yes']\", \"['Goal: No, Activity: No, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: Yes, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: Yes, Activity: Yes, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: Yes, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: Yes, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: No, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: Yes, Innovation: Yes, Tactics: No, Relevance: Yes']\", \"['Goal: No, Activity: Yes, Strategy: No, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: Yes, Activity: No, Strategy: Yes, Plan: Yes, Structure: No, Innovation: No, Tactics: Yes, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: Yes, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: Yes, Activity: Yes, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: Yes, Strategy: Yes, Plan: No, Structure: No, Innovation: Yes, Tactics: No, Relevance: No']\", \"['Goal: No, Activity: No, Strategy: No, Plan: No, Structure: No, Innovation: No, Tactics: No, Relevance: No']\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate predicted test dataset\n",
        "The predicted dimensions for each of the sentence in the test dataset is concatenated to the test dataset and saved in the folder."
      ],
      "metadata": {
        "id": "FY0rUTDjUNFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_predictions(df_test, predictions):\n",
        "    # Clean up the predictions by removing extra characters and splitting by commas\n",
        "    cleaned_predictions = [item[2:-2].split(', ') for item in predictions]\n",
        "\n",
        "    # Create a DataFrame with columns based on the cleaned predictions\n",
        "    df_test_prediction = pd.DataFrame(cleaned_predictions, columns=['Goal', 'Activity', 'Strategy', 'Plan', 'Structure', 'Innovation', 'Tactics', 'Relevance'])\n",
        "\n",
        "    # Adjusting the values in each column to retain only the value after ':'\n",
        "    for col in df_test_prediction.columns:\n",
        "        df_test_prediction[col] = df_test_prediction[col].apply(lambda x: x.split(': ')[1])\n",
        "\n",
        "    # Concatenate the preprocessed dataset with the predictions\n",
        "    final_test_df = pd.concat([df_test, df_test_prediction], axis=1)\n",
        "\n",
        "    return final_test_df\n"
      ],
      "metadata": {
        "id": "H8mwi7HHTlE1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_df = concatenate_predictions(df_test, predictions)"
      ],
      "metadata": {
        "id": "OmeeAvqlTrOP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6FgByVWT02u",
        "outputId": "01eb72fe-4360-46ec-a85e-e414387b8fa4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                          paragraph  \\\n",
            "0           0  Chairman's Letter\\nFebruary 26, 2015\\nTo our S...   \n",
            "1           1  For Sears and Kmart, after years of work at be...   \n",
            "2           2  This isn't new for Sears. An article in the Oc...   \n",
            "3           3  Time and again, people have proclaimed our com...   \n",
            "4           4  These old stories got it partially right. Had ...   \n",
            "\n",
            "                                 processed_paragraph Goal Activity Strategy  \\\n",
            "0  chairman's letter\\nfebruary 26, 2015\\nto our s...   No      Yes      Yes   \n",
            "1  for sears and kmart, after years of work at be...   No      Yes      Yes   \n",
            "2  this isn't new for sears. an article in the oc...   No       No       No   \n",
            "3  time and again, people have proclaimed our com...   No       No       No   \n",
            "4  these old stories got it partially right. had ...   No      Yes      Yes   \n",
            "\n",
            "  Plan Structure Innovation Tactics Relevance  \n",
            "0  Yes       Yes        Yes      No        No  \n",
            "1  Yes        No        Yes      No        No  \n",
            "2   No        No         No     Yes        No  \n",
            "3   No        No         No      No        No  \n",
            "4   No        No        Yes      No        No  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loc = \"/content/drive/MyDrive/GRA_KU_Assessment/TEST/test_data_predictions.xlsx\"\n",
        "final_test_df.to_excel(loc)"
      ],
      "metadata": {
        "id": "6DpCUY2Yy8h8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XiNtmeC005m"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}